---
title: "Testing Race Prediction Methods: Georgia"
author: "Chris Iyer"
date: "1/4/2023"
output: html_document
---

```{r}
library(tidyverse)
library(future)
library(future.callr)
```

```{r}
# # Load voter files from 2020 and 2022
# datapath <- '/Users/chrisiyer/_Current/alc/GA absentee/CI-GA_2020_2022_Elections/data/'
# voters20 <- read.table(paste(datapath, 'voters2020.txt', sep = ''),
#                         header=TRUE, sep="|", fill = TRUE, quote = "")
# 
# voters22 <- read.table(paste(datapath, 'voters2022.txt', sep = ''),
#                         header=FALSE, sep="|", fill = TRUE, quote = "")
# colnames(voters22) <- colnames(voters20) # this one lacks header so need to add
```

```{r}
# # select just name and race; merge the two files
# cols <- c('REGISTRATION_NUMBER','FIRST_NAME','MIDDLE_MAIDEN_NAME','LAST_NAME', 'RACE', 'GENDER', 'BIRTHDATE', 'COUNTY_CODE', 'COUNTY_PRECINCT_ID', 'RESIDENCE_HOUSE_NUMBER', 'RESIDENCE_STREET_NAME', 'RESIDENCE_CITY', 'RESIDENCE_ZIPCODE')
# 
# df <- merge(voters20[,cols], voters22[,cols], all = TRUE)
# df <- df %>% filter( !(RACE %in% c('', 'U')) )
# 
# write.csv(df, '/Users/chrisiyer/_Current/alc/_TX voters/GAlist_merged_cut.csv')
```

## Start here
```{r}
df <- read.csv('GAlist_merged_nonan.csv')
# include_other <- F
# if (!include_other) {
#   df <- df %>% filter(RACE != 'OT') # for now
# }
# #rename a couple columns for wru later
# colnames(df)[which(names(df) == 'LAST_NAME')] <- 'surname'
# colnames(df)[which(names(df) == 'FIRST_NAME')] <- 'first'
# 
# df$state <- 'GA'
# 
# df <- df[,-1]
# df <- df[,-1]
# 
# # deal with county codes:
# # county_codes <- read.csv('GWCounty_Number_List.csv') # just to see names
# # county_codes$fips <- read.csv('GA_FIPS_Codes.csv')$fips_county 
# fips <- read.csv('GA_FIPS_Codes.csv')$fips_county #alphabetical so it matches
# df$county <- str_pad(fips[df$COUNTY_CODE], 3, pad = '0')  # this is the FIPS county. just named 'county' b/c wru wants that
# 
# df$address_full <- paste(df$RESIDENCE_HOUSE_NUMBER, df$RESIDENCE_STREET_NAME)

head(df)
```

```{r}
all_preds <- read.csv('GA_predictions.csv')
```



quantify sensitivity and PPV of each prediction method for each race
```{r}
# sensitivity (#asian_correct / #total_asian) and PPV (#asian_correct / #total_pred_asian)
results <- function(preds, truth) {
  for (i in unique(preds)) { # for each race in df$RACE
    if (!is.na(i) & i != 'OT') {
      corr <- sum(preds==i & preds==truth)
      sens <- corr / sum(truth==i)
      ppv <- corr / sum(preds==i)
      print(paste('Race:', i, ' Sensitivity:', round(sens,4), ' PPV:', round(ppv, 4)))
    }
  }
}
```


*METHOD 1*: predictrace
```{r}
library(predictrace)
```

```{r}
pr_reform <- function(preds) {
  df_arr <- c('WH', 'HP', 'BH', 'AP', 'AI')
  pr_arr <- c('white', 'hispanic', 'black', 'asian', 'american_indian') # also gives "2 races", NA, and double-combinations (OTHER)
  
  return(case_when(
    preds %in% pr_arr ~ df_arr[match(preds, pr_arr)],
    TRUE ~ 'OT'
  ))
}
```

1a: predictrace surname only
```{r}
pr_lastname <- predictrace::predict_race(df$surname)
results(pr_reform(pr_lastname$likely_race), df$RACE)
```

1b: predictrace first name only
```{r}
pr_firstname <- predictrace::predict_race(df$first, surname=FALSE)
results(pr_reform(pr_firstname$likely_race), df$RACE)
```

1c: average the two
```{r}
pr_first_probs <- pr_firstname[,4:9]
pr_last_probs <- pr_lastname[,4:9]
pr_first_probs[is.na(pr_first_probs)] <- 0
pr_last_probs[is.na(pr_last_probs)] <- 0

pr_avg <- (pr_first_probs+ pr_last_probs) / 2

pr_avg$likely_race <- apply(pr_avg, 1, function(x) paste0(names(pr_avg)[x == max(x)], collapse = '_'))

pr_avg$likely_race <- case_when(
  pr_avg$likely_race == 'probability_white' ~ 'white',
  pr_avg$likely_race == 'probability_black' ~ 'black',
  pr_avg$likely_race == 'probability_asian' ~ 'asian',
  pr_avg$likely_race == 'probability_hispanic' ~ 'hispanic',
  pr_avg$likely_race == 'probability_american_indian' ~ 'american_indian',
  TRUE ~ '2races' # 2-races, also ties.
)
```

```{r}
results(pr_reform(pr_avg$likely_race), df$RACE)
```

```{r}
# df to contain all predictions
all_preds$pr_surname <- pr_lastname$likely_race
all_preds$pr_firstname <- pr_firstname$likely_race
all_presd$pr_avg <- pr_avg$likely_race
```




*METHOD 2*: wru
```{r}
library(wru)
census_api_key <- '07513b28b4cf6b6398a9a8838b0fc52ea632a290'

reform_wru <- function(preds) {
  return (case_when(
    preds == 'pred.whi' ~ 'WH',
    preds == 'pred.bla' ~ 'BH',
    preds == 'pred.asi' ~ 'AP',
    preds == 'pred.his' ~ 'HP',
    TRUE ~ 'OT',
  ))
}
```

2a. surname-only matching (no geocoding)
```{r}
future::plan(future::multisession)
wru_surname <- wru::predict_race(voter.file = df, surname.only = T, surname.year = '2020')
wru_surname$preds <- c('WH', 'BH', 'HP', 'AP', 'OT')[apply(wru_surname[,20:24], 1, which.max)]
results(wru_surname$preds, df$RACE)
all_preds$wru_surname <- wru_surname$preds
```

2b. county-level geolocation
```{r}
census_data <- get_census_data(key = census_api_key, census.geo = 'tract', state = c('GA'), year = '2020')
```

```{r}
df_wru <- predict_race(voter.file = df, census.geo = "county", census.key = census_api_key, year = '2020', census.data = census_data)

county_preds <- apply(df_wru[,19:23], 1, function(x) paste0(names(df_wru[,19:23])[x == max(x)], collapse = '_'))

county_preds <- reform_wru(county_preds)
```

```{r}
results(county_preds, df$RACE)
all_preds$wru_county <- county_preds
```


2c. tract-level geolocation 
```{r}
# now we're going to try to get more specific census geocoding
library(censusxy)

census_data <- get_census_data(key = census_api_key, census.geo = 'tract', state = c('GA'), year = '2020')
```

```{r}
df_geo <- cxy_geocode(df[1:1000,], street = "address_full", 
            city = "RESIDENCE_CITY", 
            state = "state", 
            zip = "RESIDENCE_ZIPCODE", 
            class = "dataframe", 
            benchmark = 'Public_AR_Census2020', 
            vintage = 'Census2020_Census2020', 
            return= 'geographies')
  
  df_geo <- df_geo %>%
    mutate(county = str_pad(as.character(cxy_county_id), 3, pad = '0'),
           tract = str_pad(as.character(cxy_tract_id), 6, pad = '0'),
           block = str_pad(as.character(cxy_block_id), 4, pad = '0')
           ) %>%
    filter(!is.na(county) & !is.na(tract) & !is.na(block)) %>%
    filter(tract %in% census_data$GA$tract$tract[which(census_data$GA$tract$county == county)])
  
  # ugh
  for (j in 1:nrow(df_geo)) {
    if (!(df_geo$tract[j] %in% census_data$GA$tract$tract[which(census_data$GA$tract$county == df_geo$county[j])])) {
      df_geo <- df_geo[-j,]
    }
  }
  # ugh ^
```

```{r}
df_wru <- predict_race(voter.file = df_geo, census.geo = "tract", census.key = census_api_key, year = '2020', census.data = census_data)

tract_preds <- apply(df_wru[,27:31], 1, function(x) paste0(names(df_wru[,27:31])[x == max(x)], collapse = '_'))

tract_preds <- reform_wru(tract_preds)
```

```{r}
print('County-level predictions: ')
results(county_preds, df$RACE)
print('Tract-level predictions: ')
results(tract_preds, df$RACE)
```

```{r}
# iterate because it takes too long at this point to run on the whole thing
cols <- c('sens_wh', 'ppv_wh', 'sens_bh', 'ppv_bh', 'sens_hp', 'ppv_hp', 'sens_ap', 'ppv_ap')
df_acc_county <- data.frame(matrix(nrow = 10, ncol = length(cols)))
colnames(df_acc_county) <- cols
df_acc_tract <- df_acc_county
df_acc_block <- df_acc_tract

add_acc <- function(df_acc, r, preds, truth) {
  row <- c()
  for (i in c('WH', 'BH', 'HP', 'AP')) { 
    corr <- sum(preds==i & preds==truth)
    row <- c(row, corr / sum(truth==i), corr / sum(preds==i) )
  }
  df_acc[r,] <- row
  return(df_acc)
}

for (i in 1:10) {
  rows <- sample(nrow(df), 10000) # randomly sample 1000 rows
  df_geo <- cxy_geocode(df[rows,], street = "address_full", 
            city = "RESIDENCE_CITY", 
            state = "state", 
            zip = "RESIDENCE_ZIPCODE", 
            class = "dataframe",
            benchmark = 'Public_AR_Census2020',
            vintage = 'Census2020_Census2020',
            return= 'geographies')
  
  df_geo <- df_geo %>%
    mutate(county = str_pad(as.character(cxy_county_id), 3, pad = '0'),
           tract = str_pad(as.character(cxy_tract_id), 6, pad = '0'),
           block = str_pad(as.character(cxy_block_id), 4, pad = '0')
           ) %>%
    filter(!is.na(county) & !is.na(tract) & !is.na(block))
  # ugh
  for (j in 1:nrow(df_geo)) {
    if (!(df_geo$tract[j] %in% census_data_block$GA$tract$tract[which(census_data_block$GA$tract$county == df_geo$county[j])])) {
      df_geo <- df_geo[-j,]
    }
    # if (!(df_geo$block[j] %in% census_data_block$GA$block$block[which(census_data_block$GA$block$tract == df_geo$tract[j])])) {
    #   df_geo <- df_geo[-j,]
    # }
  }
  # ugh ^
  
  # county preds
  df_wru <- predict_race(voter.file = df_geo, census.geo = "county", census.key = census_api_key, year = '2020', census.data = census_data_block)
  
  county_preds <- apply(df_wru[,27:31], 1, function(x) paste0(names(df_wru[,27:31])[x == max(x)], collapse = '_'))
  
  county_preds <- reform_wru(county_preds)
  
  # tract preds
  df_wru <- predict_race(voter.file = df_geo, census.geo = "tract", census.key = census_api_key, year = '2020', census.data = census_data_block)

  tract_preds <- apply(df_wru[,27:31], 1, function(x) paste0(names(df_wru[,27:31])[x == max(x)], collapse = '_'))

  tract_preds <- reform_wru(tract_preds)
  
  # block preds
  df_wru <- predict_race(voter.file = df_geo, census.geo = "block", census.key = census_api_key, year = '2020', census.data = census_data_block)

  block_preds <- apply(df_wru[,27:31], 1, function(x) paste0(names(df_wru[,27:31])[x == max(x)], collapse = '_'))

  block_preds <- reform_wru(block_preds)
  
  # save accuracy vals
  df_acc_county <- add_acc(df_acc_county, i, county_preds, df_geo$RACE)
  df_acc_tract <- add_acc(df_acc_tract, i, tract_preds, df_geo$RACE)
  df_acc_block <- add_acc(df_acc_block, i, block_preds, df_geo$RACE)
}
```


```{r}
cat('County-level prediction (across 10 random samples of 10000): \n')
colMeans(df_acc_county)
cat('\nTract-level prediction (across 10 random samples of 10000): \n')
colMeans(df_acc_tract)
cat('\nBlock-level prediction (across 10 random samples of 10000): \n')
colMeans(df_acc_block)
```

2d. block-level predictions
```{r}
census_data_block <- get_census_data(key = census_api_key, census.geo = 'block', state = c('GA'), year = '2020')
```

```{r}
# compare speed to tract-level and block_level once already have df_geo and census_data 
df_wru <- predict_race(voter.file = df_geo, census.geo = "tract", census.key = census_api_key, year = '2020', census.data = census_data_block)

tract_preds <- apply(df_wru[,27:31], 1, function(x) paste0(names(df_wru[,27:31])[x == max(x)], collapse = '_'))
tract_preds <- reform_wru(tract_preds)

df_wru <- predict_race(voter.file = df_geo, census.geo = "block", census.key = census_api_key, year = '2020', census.data = census_data_block)

block_preds <- apply(df_wru[,27:31], 1, function(x) paste0(names(df_wru[,27:31])[x == max(x)], collapse = '_'))
block_preds <- reform_wru(block_preds)
```




```{r}
# block altogether
census_data_block <- get_census_data(key = census_api_key, census.geo = 'block', state = c('GA'), year = '2020')

df_geo_full <- cxy_geocode(df, street = "address_full", 
            city = "RESIDENCE_CITY", 
            state = "state", 
            zip = "RESIDENCE_ZIPCODE", 
            class = "dataframe",
            benchmark = 'Public_AR_Census2020',
            vintage = 'Census2020_Census2020',
            return= 'geographies')
df_geo_full

df_wru <- predict_race(voter.file = df_geo, census.geo = "block", census.key = census_api_key, year = '2020', census.data = census_data)

block_preds <- apply(df_wru[,27:31], 1, function(x) paste0(names(df_wru[,27:31])[x == max(x)], collapse = '_'))

block_preds <- reform_wru(tract_preds)
```





*METHOD 3*: Mixing predictions
```{r}
test <- case_when(
  all_preds$wru_geo == 'AP' | all_preds$pr_avg == 'AP' | (all_preds$et_fl_other == 'AP' & all_preds$et_fl == 'AP') ~ 'AP' ,
  T ~ 'WH'
)

corr <- sum(test=='AP' & test==all_preds$truth)
sens <- corr / sum(all_preds$truth=='AP')
ppv <- corr / sum(test=='AP')
print(paste('Sensitivity:', round(sens,4), ' PPV:', round(ppv, 4)))

# just looking for AP sens & PPV; ideally both are above 80%
```

```{r}
all_preds$test_balanced <- test
```

```{r}
# with this somewhat balanced solution, we'll see now how reliable it is across 10 random samples of 10k voters
for (i in 1:10) { 
  curr <- all_preds[sample(nrow(all_preds), 10000), ] # random 10k rows
  corr <- sum(curr$test_balanced=='AP' & curr$test_balanced==curr$truth)
  sens <- corr / sum(curr$truth=='AP')
  ppv <- corr / sum(curr$test_balanced=='AP')
  print(paste('Sensitivity:', round(sens,4), ' PPV:', round(ppv, 4)))
}
```



